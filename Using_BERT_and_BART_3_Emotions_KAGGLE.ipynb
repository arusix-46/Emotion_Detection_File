{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9897715,"sourceType":"datasetVersion","datasetId":6079689}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:43:16.065382Z","iopub.execute_input":"2024-11-14T13:43:16.066050Z","iopub.status.idle":"2024-11-14T13:43:27.555598Z","shell.execute_reply.started":"2024-11-14T13:43:16.066003Z","shell.execute_reply":"2024-11-14T13:43:27.554598Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertTokenizer, BartForConditionalGeneration, BartTokenizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom transformers import BertModel, AdamW\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:41:57.137041Z","iopub.execute_input":"2024-11-14T13:41:57.137432Z","iopub.status.idle":"2024-11-14T13:42:07.150491Z","shell.execute_reply.started":"2024-11-14T13:41:57.137393Z","shell.execute_reply":"2024-11-14T13:42:07.149645Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_excel('/kaggle/input/emotions-d/5247-rows_3-Emotions_No-Type.xlsx')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:42:42.076118Z","iopub.execute_input":"2024-11-14T13:42:42.076491Z","iopub.status.idle":"2024-11-14T13:42:43.283519Z","shell.execute_reply.started":"2024-11-14T13:42:42.076455Z","shell.execute_reply":"2024-11-14T13:42:43.282503Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Extract input (Utterance) and target (Emotion)\nX = data['Utterance'].values\ny = data['Emotion'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:42:51.472825Z","iopub.execute_input":"2024-11-14T13:42:51.474037Z","iopub.status.idle":"2024-11-14T13:42:51.484700Z","shell.execute_reply.started":"2024-11-14T13:42:51.473976Z","shell.execute_reply":"2024-11-14T13:42:51.483539Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Label encode 'Emotion' with new values [-1, 0, 1]\nlabel_encoder_emotion = LabelEncoder()\ny = label_encoder_emotion.fit_transform(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:42:57.076698Z","iopub.execute_input":"2024-11-14T13:42:57.077556Z","iopub.status.idle":"2024-11-14T13:42:57.085479Z","shell.execute_reply.started":"2024-11-14T13:42:57.077513Z","shell.execute_reply":"2024-11-14T13:42:57.084584Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Label encode 'Dialogue_Act'\nlabel_encoder_dialogue_act = LabelEncoder()\ndialogue_act_encoded = label_encoder_dialogue_act.fit_transform(data['Dialogue_Act'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:43:02.386585Z","iopub.execute_input":"2024-11-14T13:43:02.386964Z","iopub.status.idle":"2024-11-14T13:43:02.393613Z","shell.execute_reply.started":"2024-11-14T13:43:02.386924Z","shell.execute_reply":"2024-11-14T13:43:02.392277Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Train-test split\nX_train, X_test, y_train, y_test, dialogue_act_train, dialogue_act_test = train_test_split(\n    X, y, dialogue_act_encoded, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:43:07.385871Z","iopub.execute_input":"2024-11-14T13:43:07.386793Z","iopub.status.idle":"2024-11-14T13:43:07.394953Z","shell.execute_reply.started":"2024-11-14T13:43:07.386748Z","shell.execute_reply":"2024-11-14T13:43:07.394093Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Initialize BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:43:46.045185Z","iopub.execute_input":"2024-11-14T13:43:46.045677Z","iopub.status.idle":"2024-11-14T13:43:46.296456Z","shell.execute_reply.started":"2024-11-14T13:43:46.045629Z","shell.execute_reply":"2024-11-14T13:43:46.295613Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Tokenize the utterances\ndef tokenize_data(text_list):\n    return tokenizer(\n        text_list,\n        padding=True,\n        truncation=True,\n        max_length=128,\n        return_tensors='pt'\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:43:51.956930Z","iopub.execute_input":"2024-11-14T13:43:51.957696Z","iopub.status.idle":"2024-11-14T13:43:51.962358Z","shell.execute_reply.started":"2024-11-14T13:43:51.957654Z","shell.execute_reply":"2024-11-14T13:43:51.961281Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_encodings = tokenize_data(X_train.astype(str).tolist())\ntest_encodings = tokenize_data(X_test.astype(str).tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:43:58.812477Z","iopub.execute_input":"2024-11-14T13:43:58.813386Z","iopub.status.idle":"2024-11-14T13:44:03.987392Z","shell.execute_reply.started":"2024-11-14T13:43:58.813334Z","shell.execute_reply":"2024-11-14T13:44:03.986481Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# PyTorch Dataset Class\nclass EmotionDataset(Dataset):\n    def __init__(self, encodings, dialogue_act, labels):\n        self.encodings = encodings\n        self.dialogue_act = dialogue_act\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['dialogue_act'] = torch.tensor(self.dialogue_act[idx], dtype=torch.long)\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:44:08.460212Z","iopub.execute_input":"2024-11-14T13:44:08.460583Z","iopub.status.idle":"2024-11-14T13:44:08.467658Z","shell.execute_reply.started":"2024-11-14T13:44:08.460549Z","shell.execute_reply":"2024-11-14T13:44:08.466645Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Initialize datasets and data loaders\ntrain_dataset = EmotionDataset(train_encodings, dialogue_act_train, y_train)\ntest_dataset = EmotionDataset(test_encodings, dialogue_act_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:44:17.119524Z","iopub.execute_input":"2024-11-14T13:44:17.119905Z","iopub.status.idle":"2024-11-14T13:44:17.124714Z","shell.execute_reply.started":"2024-11-14T13:44:17.119868Z","shell.execute_reply":"2024-11-14T13:44:17.123702Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Custom BERT Model with Embeddings for Dialogue Act\nclass BertWithAdditionalFeatures(nn.Module):\n    def __init__(self, bert_model, dialogue_act_vocab_size, embedding_dim, num_labels):\n        super(BertWithAdditionalFeatures, self).__init__()\n        self.bert = bert_model\n        self.dialogue_act_embedding = nn.Embedding(dialogue_act_vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(bert_model.config.hidden_size + embedding_dim, num_labels)\n\n    def forward(self, input_ids, attention_mask, dialogue_act):\n        # Get BERT embeddings\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs[1]\n\n        # Get embedding for Dialogue Act\n        dialogue_act_embedded = self.dialogue_act_embedding(dialogue_act)\n\n        # Concatenate BERT output with Dialogue Act embeddings\n        combined_output = torch.cat((pooled_output, dialogue_act_embedded), dim=1)\n\n        # Pass through fully connected layer\n        output = self.fc(self.dropout(combined_output))\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:44:23.063164Z","iopub.execute_input":"2024-11-14T13:44:23.063806Z","iopub.status.idle":"2024-11-14T13:44:23.071360Z","shell.execute_reply.started":"2024-11-14T13:44:23.063766Z","shell.execute_reply":"2024-11-14T13:44:23.070318Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Training parameters\nbatch_size = 16\nlearning_rate = 5e-5\nepochs = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:45:41.610794Z","iopub.execute_input":"2024-11-14T13:45:41.611214Z","iopub.status.idle":"2024-11-14T13:45:41.615755Z","shell.execute_reply.started":"2024-11-14T13:45:41.611172Z","shell.execute_reply":"2024-11-14T13:45:41.614739Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Initialize data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:45:51.560949Z","iopub.execute_input":"2024-11-14T13:45:51.561848Z","iopub.status.idle":"2024-11-14T13:45:51.566618Z","shell.execute_reply.started":"2024-11-14T13:45:51.561805Z","shell.execute_reply":"2024-11-14T13:45:51.565656Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Initialize the BERT model and the custom model\nbert_model = BertModel.from_pretrained('bert-base-uncased')\nmodel = BertWithAdditionalFeatures(\n    bert_model=bert_model,\n    dialogue_act_vocab_size=len(label_encoder_dialogue_act.classes_),\n    embedding_dim=16,\n    num_labels=len(label_encoder_emotion.classes_)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:46:03.937978Z","iopub.execute_input":"2024-11-14T13:46:03.938889Z","iopub.status.idle":"2024-11-14T13:46:04.285856Z","shell.execute_reply.started":"2024-11-14T13:46:03.938843Z","shell.execute_reply":"2024-11-14T13:46:04.284927Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Move model to GPU if available\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:46:10.849834Z","iopub.execute_input":"2024-11-14T13:46:10.850260Z","iopub.status.idle":"2024-11-14T13:46:11.274201Z","shell.execute_reply.started":"2024-11-14T13:46:10.850213Z","shell.execute_reply":"2024-11-14T13:46:11.273256Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"BertWithAdditionalFeatures(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dialogue_act_embedding): Embedding(59, 16)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=784, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from torch.optim import AdamW  # Import AdamW from torch.optim\n\n# Initialize optimizer and loss function\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:46:23.727332Z","iopub.execute_input":"2024-11-14T13:46:23.728199Z","iopub.status.idle":"2024-11-14T13:46:24.567627Z","shell.execute_reply.started":"2024-11-14T13:46:23.728159Z","shell.execute_reply":"2024-11-14T13:46:24.566860Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Training loop\nmodel.train()\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    for batch in tqdm(train_loader):\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        outputs = model(\n            input_ids=batch['input_ids'],\n            attention_mask=batch['attention_mask'],\n            dialogue_act=batch['dialogue_act']\n        )\n        loss = criterion(outputs, batch['labels'])\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    print(f\"Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:46:32.881885Z","iopub.execute_input":"2024-11-14T13:46:32.882485Z","iopub.status.idle":"2024-11-14T13:50:57.830925Z","shell.execute_reply.started":"2024-11-14T13:46:32.882443Z","shell.execute_reply":"2024-11-14T13:50:57.829813Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:23<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.10565388202667236\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:30<00:00,  2.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.06407688558101654\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:30<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"Loss: 0.06446914374828339\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\npredictions, true_labels = [], []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(\n            input_ids=batch['input_ids'],\n            attention_mask=batch['attention_mask'],\n            dialogue_act=batch['dialogue_act']\n        )\n\n        logits = outputs\n        predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n        true_labels.extend(batch['labels'].cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:51:11.232312Z","iopub.execute_input":"2024-11-14T13:51:11.232702Z","iopub.status.idle":"2024-11-14T13:51:18.723301Z","shell.execute_reply.started":"2024-11-14T13:51:11.232664Z","shell.execute_reply":"2024-11-14T13:51:18.722503Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Calculate accuracy and classification report\naccuracy = accuracy_score(true_labels, predictions)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\ntarget_names = [str(class_) for class_ in label_encoder_emotion.classes_]\nreport = classification_report(true_labels, predictions, target_names=target_names)\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:51:29.890797Z","iopub.execute_input":"2024-11-14T13:51:29.891750Z","iopub.status.idle":"2024-11-14T13:51:29.916551Z","shell.execute_reply.started":"2024-11-14T13:51:29.891705Z","shell.execute_reply":"2024-11-14T13:51:29.915577Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.8571\n              precision    recall  f1-score   support\n\n          -1       0.69      0.62      0.65       212\n           0       0.90      0.93      0.91       827\n           1       0.17      0.09      0.12        11\n\n    accuracy                           0.86      1050\n   macro avg       0.59      0.55      0.56      1050\nweighted avg       0.85      0.86      0.85      1050\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# BART Summarization (for new samples longer than 15 words)\nbart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\nbart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:52:24.766816Z","iopub.execute_input":"2024-11-14T13:52:24.767434Z","iopub.status.idle":"2024-11-14T13:52:26.901690Z","shell.execute_reply.started":"2024-11-14T13:52:24.767387Z","shell.execute_reply":"2024-11-14T13:52:26.900644Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def summarize_text(utterance):\n    if len(utterance.split()) > 30:\n        inputs = bart_tokenizer(utterance, max_length=1024, return_tensors='pt', truncation=True)\n        summary_ids = bart_model.generate(inputs['input_ids'], max_length=50, min_length=15, length_penalty=2.0, num_beams=4, early_stopping=True)\n        return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return utterance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T13:52:35.026408Z","iopub.execute_input":"2024-11-14T13:52:35.027368Z","iopub.status.idle":"2024-11-14T13:52:35.033554Z","shell.execute_reply.started":"2024-11-14T13:52:35.027325Z","shell.execute_reply":"2024-11-14T13:52:35.032595Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Example prediction on new sample with summarization\nnew_sample = {\n    \"Utterance\": \n    \"I don’t understand why you keep changing your mind, it makes everything so much harder to follow. \n    It’s really frustrating.\",\n    \"Dialogue_Act\": \"irq\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:20:12.235093Z","iopub.execute_input":"2024-11-14T14:20:12.235533Z","iopub.status.idle":"2024-11-14T14:20:12.240738Z","shell.execute_reply.started":"2024-11-14T14:20:12.235495Z","shell.execute_reply":"2024-11-14T14:20:12.239571Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"# Summarize the utterance if necessary\nsummarized_utterance = summarize_text(new_sample['Utterance'])\nprint(f\"Summarized Utterance: {summarized_utterance}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:20:13.291781Z","iopub.execute_input":"2024-11-14T14:20:13.292435Z","iopub.status.idle":"2024-11-14T14:20:13.297313Z","shell.execute_reply.started":"2024-11-14T14:20:13.292389Z","shell.execute_reply":"2024-11-14T14:20:13.296391Z"}},"outputs":[{"name":"stdout","text":"Summarized Utterance: I don’t understand why you keep changing your mind, it makes everything so much harder to follow. It’s really frustrating.\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"# Tokenize and encode Dialogue Act\nnew_utterance_encoding = tokenize_data([summarized_utterance])\nencoded_dialogue_act = torch.tensor(label_encoder_dialogue_act.transform([new_sample['Dialogue_Act']]), dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:20:14.879623Z","iopub.execute_input":"2024-11-14T14:20:14.880403Z","iopub.status.idle":"2024-11-14T14:20:14.887133Z","shell.execute_reply.started":"2024-11-14T14:20:14.880358Z","shell.execute_reply":"2024-11-14T14:20:14.886111Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# Ensure the model is in evaluation mode\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:20:15.934988Z","iopub.execute_input":"2024-11-14T14:20:15.935931Z","iopub.status.idle":"2024-11-14T14:20:15.944860Z","shell.execute_reply.started":"2024-11-14T14:20:15.935888Z","shell.execute_reply":"2024-11-14T14:20:15.943913Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"BertWithAdditionalFeatures(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dialogue_act_embedding): Embedding(59, 16)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=784, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"with torch.no_grad():\n    input_ids = new_utterance_encoding['input_ids'].to(device)\n    attention_mask = new_utterance_encoding['attention_mask'].to(device)\n    dialogue_act = encoded_dialogue_act.to(device)\n\n    output = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask,\n        dialogue_act=dialogue_act\n    )\n\n    predicted_emotion_idx = torch.argmax(output, dim=1).cpu().numpy()[0]\n    predicted_emotion = label_encoder_emotion.inverse_transform([predicted_emotion_idx])[0]\n\nprint(f\"Predicted Emotion: {predicted_emotion}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T14:20:17.067950Z","iopub.execute_input":"2024-11-14T14:20:17.068354Z","iopub.status.idle":"2024-11-14T14:20:17.087402Z","shell.execute_reply.started":"2024-11-14T14:20:17.068315Z","shell.execute_reply":"2024-11-14T14:20:17.086518Z"}},"outputs":[{"name":"stdout","text":"Predicted Emotion: -1\n","output_type":"stream"}],"execution_count":85}]}